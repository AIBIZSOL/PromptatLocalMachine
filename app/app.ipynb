{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/path/to/project')\n",
    "sys.path.append(\"C:/Users/mmahmoud/localGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ingest\n",
    "import run_localGPT\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "import requests\n",
    "from googlesearch import search\n",
    "import hashlib\n",
    "import os\n",
    "import base64\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoinMarketCap_DEX_page_URL = \"https://coinmarketcap.com/rankings/exchanges/dex/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_coinmarketcap_dex_page():\n",
    "    \"\"\"\n",
    "    Scrapes the CoinMarketCap DEX page for the DEX table and writes the data to a xlsx file.\n",
    "    the table contains the name of the DEX and the link to the DEX page on CoinMarketCap.\n",
    "    url: URL of the CoinMarketCap DEX page\n",
    "    save_path: path to save the xlsx file\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the HTML content\n",
    "    html_content = requests.get(CoinMarketCap_DEX_page_URL).content\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Find the table and table rows containing the DEX information\n",
    "    table = soup.find(\"table\", {\"class\": \"sc-66133f36-3 dOrjhR cmc-table\"})\n",
    "    # table's body\n",
    "    table_body = table.find(\"tbody\")\n",
    "    table_rows = table_body.find_all(\"tr\")\n",
    "\n",
    "    # Prepare the data for the table\n",
    "    table_data = []\n",
    "    for row in table_rows:\n",
    "        columns = row.find_all(\"td\")\n",
    "        if len(columns) >= 2:\n",
    "            dex_name_elem = columns[1]\n",
    "            dex_website_elem = columns[1].find(\"a\", {\"class\": \"cmc-link\"})\n",
    "            if dex_name_elem and dex_website_elem:\n",
    "                dex_name = dex_name_elem.text\n",
    "                table_data.append(dex_name)\n",
    "\n",
    "    # Write the data to a xlsx file\n",
    "    df = pd.DataFrame(table_data, columns=[\"Dex Name\"])\n",
    "\n",
    "    # Preporcessing dex names : \n",
    "    # - Uniswap v3 (Ethereum)2\t-> Uniswap v3\n",
    "    # - if the dex id from the top 10 remove the last char if it is a digit (classement)\n",
    "\n",
    "    df[\"Dex Name\"][:10] = df[\"Dex Name\"][:10].apply(lambda x: x[:-1] if x[-1].isdigit() else x)\n",
    "    df[\"Dex Name\"] = df[\"Dex Name\"].apply(lambda x: x.split(\"(\")[0].strip())\n",
    "\n",
    "    # delete duplicates based on name and show the percentage of duplicates\n",
    "    #print(\"Percentage of duplicates : \", 100 - len(df.drop_duplicates(subset=['Dex Name'], keep='first'))/len(df)*100, \"%\")\n",
    "    df = df.drop_duplicates(subset=['Dex Name'], keep='first')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dex_list = scrape_coinmarketcap_dex_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dex_list.to_excel(\"dataframes/dex_list.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your GitHub personal access token\n",
    "TOKEN = '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'\n",
    "\n",
    "# Define the folder for storing database\n",
    "SOURCE_DIRECTORY = f\"tmp_data\"\n",
    "# Define the folder for storing the embeddings\n",
    "PERSIST_DIRECTORY = f\"tmp_persist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_url_as_html(url, save_path):\n",
    "    try:\n",
    "        # Send a GET request to the URL to fetch the content\n",
    "        response = requests.get(url, timeout=10)\n",
    "        \n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Save the content as an HTML file\n",
    "            with open(save_path, 'w', encoding='utf-8') as html_file:\n",
    "                html_file.write(response.text)\n",
    "            print(f\"HTML content saved as {save_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch the URL. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "def get_documents(dex_name, save_path=SOURCE_DIRECTORY):\n",
    "    # Extract links for liquidity model using googlesearch (only html files)\n",
    "    query = f'{dex_name} liquidity model'\n",
    "    search_results = search(query, num_results=1)\n",
    "    liquidity_model_link = list(search_results)\n",
    "\n",
    "    # create a folder for the dex liquidity model\n",
    "    os.makedirs(f'{save_path}/{dex_name}/liquidity_model', exist_ok=True)\n",
    "\n",
    "    # save liquidity model pages as html\n",
    "    for i, link in enumerate(liquidity_model_link):\n",
    "        try:\n",
    "            save_url_as_html(link, f'{save_path}/{dex_name}/liquidity_model/{hashlib.md5(link.encode()).hexdigest()}_{i+1}.html')\n",
    "        except:\n",
    "            print(\"Could not save the page.\")\n",
    "\n",
    "    # create a folder for the dex if it doesn't exist\n",
    "    os.makedirs(f'{save_path}/{dex_name}/license', exist_ok=True)\n",
    "    # Flag to track if a license has been found for this DEX\n",
    "    license_found = False\n",
    "    \n",
    "    # Make a GitHub API repository search request based on the DEX name\n",
    "    search_url = f'https://api.github.com/search/repositories?q={dex_name}&per_page=10'\n",
    "    headers = {'Authorization': f'token {TOKEN}'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        search_results = response.json()['items']\n",
    "\n",
    "        for repo in search_results:\n",
    "            # Check if a license file exists and retrieve the license text\n",
    "            license_url = f'https://api.github.com/repos/{repo[\"owner\"][\"login\"]}/{repo[\"name\"]}/license'\n",
    "            response = requests.get(license_url, headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                license_data = response.json()\n",
    "                if 'content' in license_data:\n",
    "                    license_text = base64.b64decode(license_data['content']).decode('utf-8')\n",
    "                    # Save license text to a file in the dex folder in the license folder \n",
    "                    with open(f'{save_path}/{dex_name}/license/{repo[\"full_name\"].replace(\"/\", \"__\")}.txt', 'w') as f:\n",
    "                        f.write(license_text)\n",
    "                    # Set the flag to True to indicate that a license has been found\n",
    "                    license_found = True\n",
    "                    break  # Stop searching for licenses in other repositories for this DEX\n",
    "            else:\n",
    "                print(f'Failed to fetch license for {repo[\"full_name\"]}: {response.status_code}')\n",
    "    \n",
    "        # If no official license is found, create a txt file with the message\n",
    "        if not license_found:\n",
    "            with open(f'{save_path}/{dex_name}/license/no_license.txt', 'w') as f:\n",
    "                f.write(\"No official license found for this DEX.\")\n",
    "    else:\n",
    "        print(f'Failed to search for repositories related to {dex_name}: {response.status_code}')\n",
    "    \n",
    "    # return path to the dex folder\n",
    "    return f'{save_path}/{dex_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_interaction(dex_name, k, co, cs, progress=gr.Progress()):\n",
    "    results = {}\n",
    "\n",
    "    # Check if all parameters are provided\n",
    "    if dex_name and k is not None and co is not None and cs is not None:\n",
    "        progress(0.2, desc=\"Scraping documents...\")\n",
    "        #time.sleep(1)\n",
    "        #dex_folder = get_documents(dex_name) # SOURCE_DIRECTORY/dex_name\n",
    "        dex_folder = f\"{SOURCE_DIRECTORY}/{dex_name}\"\n",
    "\n",
    "        progress(0.4, desc=\"Loading embedding model...\")\n",
    "        #time.sleep(1)\n",
    "        #embedding_model = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": \"cpu\"})\n",
    "\n",
    "        progress(0.6, desc=\"Loading LLM model...\")\n",
    "        #time.sleep(1)\n",
    "        #llm = run_localGPT.load_model(device_type=\"cpu\", model_id=\"TheBloke/Llama-2-7b-Chat-GGUF\", model_basename=\"llama-2-7b-chat.Q4_K_M.gguf\")\n",
    "\n",
    "        # Define features to process\n",
    "        features = [\"liquidity_model\", \"license\"]\n",
    "        \n",
    "        for feature in features:\n",
    "            source_directory = f\"{dex_folder}/{feature}\"\n",
    "            #progress(0.5, desc=\"Ingesting documents...\")\n",
    "            #time.sleep(1)\n",
    "            #save_path = f\"{source_directory}/{embedding_model.model_name}\"\n",
    "            #save_path = f\"{PERSIST_DIRECTORY}/{dex_name}/{feature}/{embedding_model.model_name.replace('/', '_')}\"\n",
    "            # Convert chunk_size and chunk_overlap to integers\n",
    "            cs = int(cs)\n",
    "            co = int(co)\n",
    "            #ingest.main(device_type=\"cpu\", embedding_model=embedding_model, chunk_size=cs, chunk_overlap=co,\n",
    "                        #source_directory=source_directory, save_path=save_path)\n",
    "            \n",
    "            #persist_directory = os.path.join(save_path, f'cs_{cs}_co_{co}')\n",
    "\n",
    "            # Getting the query from queries/feature.txt\n",
    "            with open(f\"../queries/{feature}.txt\", \"r\") as f:\n",
    "                query = f.read()\n",
    "                query = query.replace(\"the DEX\", dex_name)\n",
    "\n",
    "            # Convert k to an integer\n",
    "            k = int(k)\n",
    "\n",
    "            # Running localGPT\n",
    "            #progress(1, desc=\"Running localGPT...\")\n",
    "            #time.sleep(1)\n",
    "            #answer, docs = run_localGPT.main(\"cpu\", llm, k, persist_directory, query, verbose=False, show_sources=False, promptTemplate_type=\"llama\")\n",
    "\n",
    "            # Store the results\n",
    "            #results[feature] = {\"answer\": answer, \"sources\": [document.page_content for document in docs]}\n",
    "        results[\"liquidity_model\"] ={\"answer\":  \"Yes\"}\n",
    "        results[\"license\"] ={\"answer\":  \" NO\"}\n",
    "        # After obtaining the results, update the DataFrame\n",
    "        if dex_name:\n",
    "            # Assuming you have obtained features from the results\n",
    "            features = list(results.keys())\n",
    "            new_row = {\"Dex name\": dex_name}\n",
    "\n",
    "        for feature in features:\n",
    "            new_row[feature] = \"YESS\"\n",
    "\n",
    "        # Append the new row to the DataFrame\n",
    "        df = pd.read_excel(\"dataframes/table.xlsx\")\n",
    "        # Concatenate the new row with the DataFrame if the row doesn't already exist\n",
    "        # Otherwise, update the row\n",
    "        if dex_name in df[\"Dex name\"].values:\n",
    "            for feature in features:\n",
    "                df.loc[df[\"Dex name\"] == dex_name, feature] = new_row[feature]\n",
    "        else:\n",
    "            df = pd.concat([df, pd.DataFrame(new_row, index=[0])])\n",
    "        df.to_excel(\"dataframes/table.xlsx\", index=False)\n",
    "        # Unload the model and free up resources\n",
    "        #del llm\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution1 = \"C:/Users/mmahmoud/Pictures/chatwdoc (1).png\"\n",
    "solution2 = \"C:/Users/mmahmoud/Pictures/chatwdoc (2).png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Dex name\": [\"Uniswap v3\", \"SushiSwap\", \"PancakeSwap\"], \"liquidity_model\": [\"LM1\", \"LM2\", \"LM3\"], \"license\": [\"MIT\", \"Apache\", \"GPL\"]})\n",
    "df.to_excel(\"dataframes/table.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7879\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7879/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with gr.Blocks(gr.themes.Default()) as demo:\n",
    "    # title\n",
    "    gr.Markdown(\"<h1 style='color: #4285F4; font-size: 36px;'>DEX Navigator</h1>\")\n",
    "    gr.Markdown(\"<p style='font-size: 20px;'>An app that helps you find answers to questions about a DEX.</p>\")\n",
    "    with gr.Tab(\"Table\"):\n",
    "\n",
    "        table = gr.Dataframe(\n",
    "            headers=[\"DEX name\", \"Liquidity Model\", \"License\"],\n",
    "            datatype=[\"str\", \"str\", \"str\"],\n",
    "            value = pd.read_excel(\"dataframes/table.xlsx\")\n",
    "        )\n",
    "        refresh_button = gr.Button(\"Refresh Table\")\n",
    "        def refresh_table():\n",
    "            table = gr.Dataframe(\n",
    "                headers=[\"DEX name\", \"Liquidity Model\", \"License\"],\n",
    "                datatype=[\"str\", \"str\", \"str\"],\n",
    "                value=pd.read_excel(\"dataframes/table.xlsx\")\n",
    "            )\n",
    "            return table\n",
    "        refresh_button.click(refresh_table, outputs=[table])\n",
    "\n",
    "    \n",
    "    with gr.Tab(\"Interact with the app\"):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    dex = gr.Dropdown(label=\"DEX Name\", choices=pd.read_excel(\"dataframes/dex_list.xlsx\")[\"Dex Name\"].tolist(), value=\"Uniswap v3\")\n",
    "                    gr.Slider(minimum=0, maximum=1, value=0, label=\"Temperature\", info=\"Choose between 0 and 1\")\n",
    "                    gr.Slider(minimum=0, maximum=1, value=0, label=\"Top P\", info=\"Choose between 0 and 1\")\n",
    "                with gr.Column(\"Ingesting Parameters\"):\n",
    "                    cs = gr.Number(label=\"Chunk Size\", value=500) \n",
    "                    co = gr.Number(label=\"Chunk Overlap\", value=100)\n",
    "                    k = gr.Number(label=\"Number of Chunks\", minimum=1, maximum=5, value=3, info=\"Choose between 1 and 5\")              \n",
    "            with gr.Column():\n",
    "                results = gr.JSON(label=\"Results\")\n",
    "        with gr.Row():\n",
    "            extract_button = gr.Button(\"Extract\")\n",
    "            update_dex_list_button = gr.Button(\"Update DEX List\")\n",
    "\n",
    "    extract_button.click(user_interaction, inputs=[dex, k, co, cs], outputs=[results])\n",
    "    def refresh_dex_list():\n",
    "        df_dex_list = pd.read_excel(\"dataframes/dex_list.xlsx\")\n",
    "        df = scrape_coinmarketcap_dex_page()\n",
    "        # add def to df_dex_list if not already present\n",
    "        df_dex_list = df_dex_list.append(df[~df[\"Dex Name\"].isin(df_dex_list[\"Dex Name\"])])\n",
    "        df_dex_list.to_excel(\"dataframes/dex_list.xlsx\", index=False)\n",
    "        return gr.Dropdown(label=\"DEX Name\", choices=pd.read_excel(\"dataframes/dex_list.xlsx\")[\"Dex Name\"].tolist(), value=\"Uniswap v3\")\n",
    "    update_dex_list_button.click(refresh_dex_list, outputs=[dex], show_progress=True)\n",
    "\n",
    "    with gr.Tab(\"How does it work?\"):\n",
    "        gr.Gallery(label=\"Solution\", value=[solution1, solution2], columns=2, rows=1, object_fit=\"scale-down\")\n",
    "\n",
    "demo.queue(concurrency_count=20).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
